{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9759185b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>인공지능 또는 AI는 인간의 학습능력 추론능력 지각능력 그외에 인공적으로 구현한 컴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>하나의 인프라 기술이기도 하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인간을 포함한 동물이 갖고 있는 지능 즉 natural intelligence와는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지능을 갖고 있는 기능을 갖춘 컴퓨터 시스템이며 인간의 지능을 기계 등에 인공적으로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일반적으로 범용 컴퓨터에 적용한다고 가정한다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  인공지능 또는 AI는 인간의 학습능력 추론능력 지각능력 그외에 인공적으로 구현한 컴...\n",
       "1                                   하나의 인프라 기술이기도 하다\n",
       "2  인간을 포함한 동물이 갖고 있는 지능 즉 natural intelligence와는 ...\n",
       "3  지능을 갖고 있는 기능을 갖춘 컴퓨터 시스템이며 인간의 지능을 기계 등에 인공적으로...\n",
       "4                          일반적으로 범용 컴퓨터에 적용한다고 가정한다 "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import konlpy\n",
    "\n",
    "data = pd.read_csv(\"data/sample_text.csv\", header=None, names=['text'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929357bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>morphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>인공지능 또는 AI는 인간의 학습능력 추론능력 지각능력 그외에 인공적으로 구현한 컴...</td>\n",
       "      <td>[인공지능, 또는, AI, 는, 인간, 의, 학습, 능력, 추론, 능력, 지각, 능...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>하나의 인프라 기술이기도 하다</td>\n",
       "      <td>[하나, 의, 인프라, 기술, 이, 기, 도, 하, 다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인간을 포함한 동물이 갖고 있는 지능 즉 natural intelligence와는 ...</td>\n",
       "      <td>[인간, 을, 포함, 한, 동물, 이, 갖, 고, 있, 는, 지능, 즉, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지능을 갖고 있는 기능을 갖춘 컴퓨터 시스템이며 인간의 지능을 기계 등에 인공적으로...</td>\n",
       "      <td>[지능, 을, 갖, 고, 있, 는, 기능, 을, 갖춘,  , 컴퓨터, 시스템, 이,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일반적으로 범용 컴퓨터에 적용한다고 가정한다</td>\n",
       "      <td>[일반, 적, 으로, 범용, 컴퓨터, 에, 적용, 한다고, 가정, 한다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>이 용어는 또한 그와 같은 지능을 만들 수 있는 방법론이나 실현 가능성 등을 연구하...</td>\n",
       "      <td>[이, 용어, 는, 또한, 그, 와, 같, 은, 지능, 을, 만들, 수, 있, 는,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  인공지능 또는 AI는 인간의 학습능력 추론능력 지각능력 그외에 인공적으로 구현한 컴...   \n",
       "1                                   하나의 인프라 기술이기도 하다   \n",
       "2  인간을 포함한 동물이 갖고 있는 지능 즉 natural intelligence와는 ...   \n",
       "3  지능을 갖고 있는 기능을 갖춘 컴퓨터 시스템이며 인간의 지능을 기계 등에 인공적으로...   \n",
       "4                          일반적으로 범용 컴퓨터에 적용한다고 가정한다    \n",
       "5  이 용어는 또한 그와 같은 지능을 만들 수 있는 방법론이나 실현 가능성 등을 연구하...   \n",
       "\n",
       "                                              morphs  \n",
       "0  [인공지능, 또는, AI, 는, 인간, 의, 학습, 능력, 추론, 능력, 지각, 능...  \n",
       "1                    [하나, 의, 인프라, 기술, 이, 기, 도, 하, 다]  \n",
       "2  [인간, 을, 포함, 한, 동물, 이, 갖, 고, 있, 는, 지능, 즉, natur...  \n",
       "3  [지능, 을, 갖, 고, 있, 는, 기능, 을, 갖춘,  , 컴퓨터, 시스템, 이,...  \n",
       "4           [일반, 적, 으로, 범용, 컴퓨터, 에, 적용, 한다고, 가정, 한다]  \n",
       "5  [이, 용어, 는, 또한, 그, 와, 같, 은, 지능, 을, 만들, 수, 있, 는,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = konlpy.tag.Mecab()\n",
    "\n",
    "data['text'] = data['text'].str.replace(\",\", \"\")\n",
    "data['morphs'] = data['text'].map(lambda x: tokenizer.morphs(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c678df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = set()\n",
    "data['morphs'].map(lambda x: words.update(set(x)))\n",
    "\n",
    "word_to_index = {w: i + 4 for i, w in enumerate(words)}\n",
    "word_to_index[\"PAD\"] = 0\n",
    "word_to_index[\"UNK\"] = 1\n",
    "word_to_index[\"SOS\"] = 2\n",
    "word_to_index[\"EOS\"] = 3\n",
    "\n",
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b149449",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "chars = sorted(list(chars))\n",
    "\n",
    "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char_to_index[\"PAD\"] = 0\n",
    "char_to_index[\"UNK\"] = 1\n",
    "\n",
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f70c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_char = 10\n",
    "max_len_word = 50\n",
    "\n",
    "def integer_coding(sentences, max_len_char, max_len_word):\n",
    "    word_data = []\n",
    "    \n",
    "    for i, word in enumerate(sentences):\n",
    "        word_data.append(word_to_index[word])\n",
    "        char_indice = [[char_to_index[char] for char in word]]\n",
    "        char_indice = pad_sequences(char_indice, maxlen=max_len_char, padding='post', value=0)\n",
    "\n",
    "        for chars_of_token in char_indice:\n",
    "            if len(chars_of_token) > max_len_char:\n",
    "                continue\n",
    "        \n",
    "        if i == 0:\n",
    "            char_data = char_indice\n",
    "        else:\n",
    "            char_data = np.vstack([char_data, char_indice])\n",
    "    \n",
    "    pad_char_data = max_len_word - char_data.shape[0]\n",
    "    \n",
    "    char_data = np.pad(char_data, ((0, pad_char_data), (0, 0)), 'constant', constant_values=0)\n",
    "    word_data = pad_sequences([word_data], maxlen=max_len_word, padding='post', value=0)\n",
    "    \n",
    "    return word_data, char_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d8bd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['인공지능',\n",
       " '또는',\n",
       " 'AI',\n",
       " '는',\n",
       " '인간',\n",
       " '의',\n",
       " '학습',\n",
       " '능력',\n",
       " '추론',\n",
       " '능력',\n",
       " '지각',\n",
       " '능력',\n",
       " '그',\n",
       " '외',\n",
       " '에',\n",
       " '인공',\n",
       " '적',\n",
       " '으로',\n",
       " '구현',\n",
       " '한',\n",
       " '컴퓨터',\n",
       " '프로그램',\n",
       " '또는',\n",
       " '이',\n",
       " '를',\n",
       " '포함',\n",
       " '한',\n",
       " '컴퓨터',\n",
       " '시스템',\n",
       " '이',\n",
       " '다']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0, \"morphs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c6a1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79, 32,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [70,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [18,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [23,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [75,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [31,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [28, 32,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [70,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [18, 81,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [14,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [83, 87, 84,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [59, 57, 85,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [72,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [47,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [73, 17,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [71,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [79, 32,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [70,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [28, 22,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [37,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [63,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [73, 24,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [76,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [68, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [59, 64,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [91,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [21,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [72,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [33,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_word_data, X_char_data = integer_coding(data.loc[3, \"morphs\"], max_len_char, max_len_word)\n",
    "X_char_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b8f5717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 60, 68, 42, 38,  7, 71, 60, 63, 11, 40,  6, 72, 12, 29, 19,\n",
       "        13, 60, 24, 73, 14,  4, 48, 41, 15, 46, 59, 72, 55,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_word_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c34f92",
   "metadata": {},
   "source": [
    "# 국민청원 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb1dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collcetions import Counter\n",
    "\n",
    "df = pd.read_table('data/test_data_cleaned.txt', header=None, names=['text']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bed4501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>morphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>국민과 소통하시고 자유롭고 행복한 나라를 만들기 위해 힘쓰고 계신 대통령께 존경과 ...</td>\n",
       "      <td>[국민, 과, 소통, 하, 시, 고, 자유, 롭, 고, 행복, 한, 나라, 를, 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기해년 새해 복 많이 받으십시오</td>\n",
       "      <td>[기해, 년, 새해, 복, 많이, 받, 으십시오]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저는 경북 울진군 북면 부구검성로 12번지에 살고 있는 북면발전협의회장 이희국이라고...</td>\n",
       "      <td>[저, 는, 경북, 울진군, 북면, 부, 구검, 성, 로, 12, 번지, 에, 살,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>저는 8기의 원전이 가동 건설되고 있는 이곳 북면에 태어나 68년째 거주하고 있는 ...</td>\n",
       "      <td>[저, 는, 8, 기, 의, 원전, 이, 가동, 건설, 되, 고, 있, 는, 이곳,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>간절한 마음을 담아 대통령께 다음과 같이 호소 드립니다</td>\n",
       "      <td>[간절, 한, 마음, 을, 담, 아, 대통령, 께, 다음, 과, 같이, 호소, 드립니다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214943</th>\n",
       "      <td>알바가 검사 안한 잘못도 있지만 미성년자가 술을 마시러 온거 자체가 잘못되었는데 업...</td>\n",
       "      <td>[알바, 가, 검사, 안, 한, 잘못, 도, 있, 지만, 미성년자, 가, 술, 을,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214944</th>\n",
       "      <td>그러므로 앞으로 미성년자의 음주가 적발될시 미성년들도 강한 처벌을 받아야하게 바꾸거...</td>\n",
       "      <td>[그러므로, 앞, 으로, 미성년자, 의, 음주, 가, 적발, 될, 시, 미성년, 들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214946</th>\n",
       "      <td>정권이 바뀐다 해도 세금이 계속 증가만 하고 내려가지는 않는데요! 어디에 어떻게 써...</td>\n",
       "      <td>[정권, 이, 바뀐다, 해도, 세금, 이, 계속, 증가, 만, 하, 고, 내려, 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214947</th>\n",
       "      <td>그리고 예산을 받아서 제대로 쓰여졌는지 감사하는 기구는 어디였고 어떠한 이유로 지연...</td>\n",
       "      <td>[그리고, 예산, 을, 받, 아서, 제대로, 쓰여졌, 는지, 감사, 하, 는, 기구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214948</th>\n",
       "      <td>진정 바라는 바는 불평등에 균형 최선이 아니라 기본에 충실해 주시길 바라는 바입니다</td>\n",
       "      <td>[진정, 바라, 는, 바, 는, 불, 평등, 에, 균형, 최선, 이, 아니, 라, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172562 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       국민과 소통하시고 자유롭고 행복한 나라를 만들기 위해 힘쓰고 계신 대통령께 존경과 ...   \n",
       "1                                       기해년 새해 복 많이 받으십시오   \n",
       "2       저는 경북 울진군 북면 부구검성로 12번지에 살고 있는 북면발전협의회장 이희국이라고...   \n",
       "3       저는 8기의 원전이 가동 건설되고 있는 이곳 북면에 태어나 68년째 거주하고 있는 ...   \n",
       "4                          간절한 마음을 담아 대통령께 다음과 같이 호소 드립니다   \n",
       "...                                                   ...   \n",
       "214943  알바가 검사 안한 잘못도 있지만 미성년자가 술을 마시러 온거 자체가 잘못되었는데 업...   \n",
       "214944  그러므로 앞으로 미성년자의 음주가 적발될시 미성년들도 강한 처벌을 받아야하게 바꾸거...   \n",
       "214946  정권이 바뀐다 해도 세금이 계속 증가만 하고 내려가지는 않는데요! 어디에 어떻게 써...   \n",
       "214947  그리고 예산을 받아서 제대로 쓰여졌는지 감사하는 기구는 어디였고 어떠한 이유로 지연...   \n",
       "214948     진정 바라는 바는 불평등에 균형 최선이 아니라 기본에 충실해 주시길 바라는 바입니다   \n",
       "\n",
       "                                                   morphs  \n",
       "0       [국민, 과, 소통, 하, 시, 고, 자유, 롭, 고, 행복, 한, 나라, 를, 만...  \n",
       "1                             [기해, 년, 새해, 복, 많이, 받, 으십시오]  \n",
       "2       [저, 는, 경북, 울진군, 북면, 부, 구검, 성, 로, 12, 번지, 에, 살,...  \n",
       "3       [저, 는, 8, 기, 의, 원전, 이, 가동, 건설, 되, 고, 있, 는, 이곳,...  \n",
       "4       [간절, 한, 마음, 을, 담, 아, 대통령, 께, 다음, 과, 같이, 호소, 드립니다]  \n",
       "...                                                   ...  \n",
       "214943  [알바, 가, 검사, 안, 한, 잘못, 도, 있, 지만, 미성년자, 가, 술, 을,...  \n",
       "214944  [그러므로, 앞, 으로, 미성년자, 의, 음주, 가, 적발, 될, 시, 미성년, 들...  \n",
       "214946  [정권, 이, 바뀐다, 해도, 세금, 이, 계속, 증가, 만, 하, 고, 내려, 가...  \n",
       "214947  [그리고, 예산, 을, 받, 아서, 제대로, 쓰여졌, 는지, 감사, 하, 는, 기구...  \n",
       "214948  [진정, 바라, 는, 바, 는, 불, 평등, 에, 균형, 최선, 이, 아니, 라, ...  \n",
       "\n",
       "[172562 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data/test_data_cleaned.txt', header=None, names=['text']).dropna()\n",
    "tokenizer = konlpy.tag.Mecab()\n",
    "\n",
    "df['text'] = df['text'].str.replace(\",\", \"\")\n",
    "df['morphs'] = df['text'].map(lambda x: tokenizer.morphs(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1711804",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 5\n",
    "\n",
    "# words = set()\n",
    "# df['morphs'].map(lambda x: words.update(set(x)))\n",
    "ct = Counter([char for line in df.morphs.values for char in line ])\n",
    "thresholded_word_vocab = [ key for key, value in ct.items() if value >= min_freq]\n",
    "\n",
    "word_to_index = {w: i + 2 for i, w in enumerate(thresholded_word_vocab)}\n",
    "word_to_index[\"PAD\"] = 0\n",
    "word_to_index[\"UNK\"] = 1\n",
    "\n",
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "859a59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars = set([w_i for w in words for w_i in w])\n",
    "chars = set([w_i for w in thresholded_word_vocab for w_i in w])\n",
    "chars = sorted(list(chars))\n",
    "\n",
    "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char_to_index[\"PAD\"] = 0\n",
    "char_to_index[\"UNK\"] = 1\n",
    "\n",
    "thresholded_char_vocab = list(char_to_index.keys())\n",
    "\n",
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90233827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "word_vocab = [index_to_word, word_to_index]\n",
    "char_vocab = [index_to_char, char_to_index]\n",
    "\n",
    "with open('data/word_vocabulary.p', 'wb') as f:\n",
    "    pickle.dump(word_vocab, f)\n",
    "\n",
    "with open('data/char_vocabulary.p', 'wb')as f:\n",
    "    pickle.dump(char_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8bb29ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_char = 6\n",
    "max_len_word = 25\n",
    "\n",
    "def integer_coding(sentences, max_len_char, max_len_word):\n",
    "    word_data = []\n",
    "    \n",
    "    for i, word in enumerate(sentences):\n",
    "        \n",
    "        if word in thresholded_vocab:\n",
    "            word_data.append(word_to_index[word])\n",
    "        elif word not in thresholded_word_vocab:\n",
    "            word_data.append(word_to_index[\"UNK\"])\n",
    "            \n",
    "        char_indice = [[char_to_index[char] if char in thresholded_char_vocab else char_to_index[\"UNK\"] for char in word]]\n",
    "        char_indice = pad_sequences(char_indice, maxlen=max_len_char, padding='post', value=0)\n",
    "\n",
    "        for chars_of_token in char_indice:\n",
    "            if len(chars_of_token) > max_len_char:\n",
    "                continue\n",
    "        \n",
    "        if i == 0:\n",
    "            char_data = char_indice\n",
    "        else:\n",
    "            char_data = np.vstack([char_data, char_indice])\n",
    "    \n",
    "    pad_char_data = max_len_word - char_data.shape[0]\n",
    "    \n",
    "    if pad_char_data > 0:\n",
    "        char_data = np.pad(char_data, ((0, pad_char_data), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        char_data = char_data[:max_len_word]\n",
    "        \n",
    "    word_data = pad_sequences([word_data], maxlen=max_len_word, padding='post', value=0)\n",
    "    \n",
    "    return np.expand_dims(word_data, 0), np.expand_dims(char_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c99f73d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>morphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>국민과 소통하시고 자유롭고 행복한 나라를 만들기 위해 힘쓰고 계신 대통령께 존경과 ...</td>\n",
       "      <td>[국민, 과, 소통, 하, 시, 고, 자유, 롭, 고, 행복, 한, 나라, 를, 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기해년 새해 복 많이 받으십시오</td>\n",
       "      <td>[기해, 년, 새해, 복, 많이, 받, 으십시오]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저는 경북 울진군 북면 부구검성로 12번지에 살고 있는 북면발전협의회장 이희국이라고...</td>\n",
       "      <td>[저, 는, 경북, 울진군, 북면, 부, 구검, 성, 로, 12, 번지, 에, 살,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>저는 8기의 원전이 가동 건설되고 있는 이곳 북면에 태어나 68년째 거주하고 있는 ...</td>\n",
       "      <td>[저, 는, 8, 기, 의, 원전, 이, 가동, 건설, 되, 고, 있, 는, 이곳,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>간절한 마음을 담아 대통령께 다음과 같이 호소 드립니다</td>\n",
       "      <td>[간절, 한, 마음, 을, 담, 아, 대통령, 께, 다음, 과, 같이, 호소, 드립니다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>앞으로 제2의 저의 자녀와 같은 장애인 취업후 사직을 강요하는 것을 바로잡고자 청원...</td>\n",
       "      <td>[앞, 으로, 제, 2, 의, 저, 의, 자녀, 와, 같, 은, 장애, 인, 취업,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>저의 자녀는 1990년생이며 2005년 교통사고 후 후유증으로 2010년 6월 9일...</td>\n",
       "      <td>[저, 의, 자녀, 는, 1990, 년, 생, 이, 며, 2005, 년, 교통사고,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>아울러 고용노동부전주지청 노동위원회에 해고무효소송을 2018년 12월 31일 했습니다</td>\n",
       "      <td>[아울러, 고용, 노동부, 전주, 지청, 노동, 위원회, 에, 해고, 무효, 소송,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>두번다시 사회적약자인 장애인채용 후 사직이라는 일이 발생되지 않도록 국민여러분의 큰...</td>\n",
       "      <td>[두, 번, 다시, 사회, 적, 약자, 인, 장애, 인, 채용, 후, 사직, 이, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>인천 구월동 한샘 상생전시장에 범죄자가 차명으로 입점하여 본인이 대표행세를 하며 고...</td>\n",
       "      <td>[인천, 구월동, 한샘, 상생, 전시장, 에, 범죄자, 가, 차명, 으로, 입점, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    국민과 소통하시고 자유롭고 행복한 나라를 만들기 위해 힘쓰고 계신 대통령께 존경과 ...   \n",
       "1                                    기해년 새해 복 많이 받으십시오   \n",
       "2    저는 경북 울진군 북면 부구검성로 12번지에 살고 있는 북면발전협의회장 이희국이라고...   \n",
       "3    저는 8기의 원전이 가동 건설되고 있는 이곳 북면에 태어나 68년째 거주하고 있는 ...   \n",
       "4                       간절한 마음을 담아 대통령께 다음과 같이 호소 드립니다   \n",
       "..                                                 ...   \n",
       "95   앞으로 제2의 저의 자녀와 같은 장애인 취업후 사직을 강요하는 것을 바로잡고자 청원...   \n",
       "96   저의 자녀는 1990년생이며 2005년 교통사고 후 후유증으로 2010년 6월 9일...   \n",
       "97     아울러 고용노동부전주지청 노동위원회에 해고무효소송을 2018년 12월 31일 했습니다   \n",
       "98   두번다시 사회적약자인 장애인채용 후 사직이라는 일이 발생되지 않도록 국민여러분의 큰...   \n",
       "100  인천 구월동 한샘 상생전시장에 범죄자가 차명으로 입점하여 본인이 대표행세를 하며 고...   \n",
       "\n",
       "                                                morphs  \n",
       "0    [국민, 과, 소통, 하, 시, 고, 자유, 롭, 고, 행복, 한, 나라, 를, 만...  \n",
       "1                          [기해, 년, 새해, 복, 많이, 받, 으십시오]  \n",
       "2    [저, 는, 경북, 울진군, 북면, 부, 구검, 성, 로, 12, 번지, 에, 살,...  \n",
       "3    [저, 는, 8, 기, 의, 원전, 이, 가동, 건설, 되, 고, 있, 는, 이곳,...  \n",
       "4    [간절, 한, 마음, 을, 담, 아, 대통령, 께, 다음, 과, 같이, 호소, 드립니다]  \n",
       "..                                                 ...  \n",
       "95   [앞, 으로, 제, 2, 의, 저, 의, 자녀, 와, 같, 은, 장애, 인, 취업,...  \n",
       "96   [저, 의, 자녀, 는, 1990, 년, 생, 이, 며, 2005, 년, 교통사고,...  \n",
       "97   [아울러, 고용, 노동부, 전주, 지청, 노동, 위원회, 에, 해고, 무효, 소송,...  \n",
       "98   [두, 번, 다시, 사회, 적, 약자, 인, 장애, 인, 채용, 후, 사직, 이, ...  \n",
       "100  [인천, 구월동, 한샘, 상생, 전시장, 에, 범죄자, 가, 차명, 으로, 입점, ...  \n",
       "\n",
       "[95 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.loc[:100, :]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee67e0c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f14d04ee0434c799aa4295863c0ed28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(95, 1, 25)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "word_array = np.array([])\n",
    "char_array = np.array([])\n",
    "\n",
    "tot = sample_df.shape[0]\n",
    "\n",
    "for i, t in tqdm(sample_df.iterrows(), total=tot):\n",
    "    word_vector, char_vector = integer_coding(t.morphs, max_len_char, max_len_word)\n",
    "\n",
    "    if i == 0:\n",
    "        word_array = word_vector\n",
    "        char_array = char_vector\n",
    "    else:\n",
    "        word_array = np.append(word_array, word_vector, axis=0)\n",
    "        char_array = np.append(char_array, char_vector, axis=0)\n",
    "        \n",
    "word_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fa7605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 25, 6)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7fd82e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 170,  678,    0,    0,    0,    0],\n",
       "       [ 157,    0,    0,    0,    0,    0],\n",
       "       [ 854, 1376,    0,    0,    0,    0],\n",
       "       [1465,    0,    0,    0,    0,    0],\n",
       "       [ 895,    0,    0,    0,    0,    0],\n",
       "       [ 146,    0,    0,    0,    0,    0],\n",
       "       [1092, 1063,    0,    0,    0,    0],\n",
       "       [ 562,    0,    0,    0,    0,    0],\n",
       "       [ 146,    0,    0,    0,    0,    0],\n",
       "       [1479,  730,    0,    0,    0,    0],\n",
       "       [1467,    0,    0,    0,    0,    0],\n",
       "       [ 276,  510,    0,    0,    0,    0],\n",
       "       [ 586,    0,    0,    0,    0,    0],\n",
       "       [ 602,  442,    0,    0,    0,    0],\n",
       "       [ 199,    0,    0,    0,    0,    0],\n",
       "       [1059, 1473,    0,    0,    0,    0],\n",
       "       [1553,  937,    0,    0,    0,    0],\n",
       "       [ 146,    0,    0,    0,    0,    0],\n",
       "       [ 145,  897,    0,    0,    0,    0],\n",
       "       [ 377, 1376,  556,    0,    0,    0],\n",
       "       [ 227,    0,    0,    0,    0,    0],\n",
       "       [1133,  143,    0,    0,    0,    0],\n",
       "       [ 157,    0,    0,    0,    0,    0],\n",
       "       [1221,  809,    0,    0,    0,    0],\n",
       "       [ 586,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eadd121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26914d3fc9d44c5a45db09fc22d3402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "word_array = np.array([])\n",
    "char_array = np.array([])\n",
    "\n",
    "tot = df.shape[0]\n",
    "\n",
    "for i, t in tqdm(df.iterrows(), total=tot):\n",
    "    word_vector, char_vector = integer_coding(t.morphs, max_len_char, max_len_word)\n",
    "\n",
    "    if i == 0:\n",
    "        word_array = word_vector\n",
    "        char_array = char_vector\n",
    "    else:\n",
    "        word_array = np.append(word_array, word_vector, axis=0)\n",
    "        char_array = np.append(char_array, char_vector, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7c0211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/word_array.npy\", word_array)\n",
    "np.save(\"data/char_array.npy\", char_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57042b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 170,  678,    0,    0,    0,    0],\n",
       "        [ 157,    0,    0,    0,    0,    0],\n",
       "        [ 854, 1376,    0,    0,    0,    0],\n",
       "        [1465,    0,    0,    0,    0,    0],\n",
       "        [ 895,    0,    0,    0,    0,    0],\n",
       "        [ 146,    0,    0,    0,    0,    0],\n",
       "        [1092, 1063,    0,    0,    0,    0],\n",
       "        [ 562,    0,    0,    0,    0,    0],\n",
       "        [ 146,    0,    0,    0,    0,    0],\n",
       "        [1479,  730,    0,    0,    0,    0],\n",
       "        [1467,    0,    0,    0,    0,    0],\n",
       "        [ 276,  510,    0,    0,    0,    0],\n",
       "        [ 586,    0,    0,    0,    0,    0],\n",
       "        [ 602,  442,    0,    0,    0,    0],\n",
       "        [ 199,    0,    0,    0,    0,    0],\n",
       "        [1059, 1473,    0,    0,    0,    0],\n",
       "        [1553,  937,    0,    0,    0,    0],\n",
       "        [ 146,    0,    0,    0,    0,    0],\n",
       "        [ 145,  897,    0,    0,    0,    0],\n",
       "        [ 377, 1376,  556,    0,    0,    0],\n",
       "        [ 227,    0,    0,    0,    0,    0],\n",
       "        [1133,  143,    0,    0,    0,    0],\n",
       "        [ 157,    0,    0,    0,    0,    0],\n",
       "        [1221,  809,    0,    0,    0,    0],\n",
       "        [ 586,    0,    0,    0,    0,    0]]], dtype=int32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_word_data, X_char_data = integer_coding(df.loc[0, \"morphs\"], max_len_char, max_len_word)\n",
    "X_char_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2e0dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3,  4,  5,  6,  7,  8,  9,  7, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "          7, 18, 19, 20, 21,  3, 22, 13, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6c5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
