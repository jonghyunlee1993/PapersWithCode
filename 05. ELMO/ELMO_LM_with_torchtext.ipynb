{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b1768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "from torchtext import data, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_source_and_target(lines, split_cond):\n",
    "    src = []\n",
    "    trg = []\n",
    "\n",
    "    for line in lines:\n",
    "        src.append(' '.join(line[:-1]) + '\\n')\n",
    "        trg.append(' '.join(line[1:]) + '\\n')\n",
    "    \n",
    "    write_txt(split_cond + \".src\", src)\n",
    "    write_txt(split_cond + \".trg\", trg)\n",
    "    \n",
    "def write_txt(fname, lines, fpath=\"data\"):\n",
    "    if fpath is not None:\n",
    "        with open(os.path.join(fpath, fname), \"w\") as f:\n",
    "            f.writelines(lines)\n",
    "    elif fpath is None:\n",
    "        with open(fname, \"w\") as f:\n",
    "            f.writelines(lines)\n",
    "\n",
    "if os.path.exists(\"data/train.src\"):\n",
    "    with open(\"data/petitions_splited_mecab.txt\", \"r\") as f:\n",
    "         corpus = f.readlines()\n",
    "\n",
    "    corpus = list(map(lambda x: str(x).replace(\"\\n\", \"\"), corpus))\n",
    "\n",
    "    train_lines, test_lines = train_test_split(corpus, test_size=0.05, random_state=1234)\n",
    "    train_lines, valid_lines = train_test_split(train_lines, test_size=1/19, random_state=1234)\n",
    "\n",
    "    generate_source_and_target(train_lines, \"train\")\n",
    "    generate_source_and_target(valid_lines, \"val\")\n",
    "    generate_source_and_target(test_lines, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c074ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source vocabulary: 1610\n",
      "Unique tokens in target vocabulary: 1602\n",
      "number of training data : 205654\n",
      "number of valid data : 11426\n",
      "number of test data : 11426\n"
     ]
    }
   ],
   "source": [
    "class ELMODataset:\n",
    "    def __init__(self, filepath, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "        self.SRC = data.Field(tokenize=lambda x: x.split(' '),\n",
    "                              init_token='<sos>',\n",
    "                              eos_token='<eos>',\n",
    "                              pad_token='<pad>',\n",
    "                              lower=True,\n",
    "                              batch_first=True,\n",
    "                              include_lengths=False)\n",
    "        \n",
    "        self.TRG = data.Field(tokenize=lambda x: x.split(' '),\n",
    "                              init_token='<sos>',\n",
    "                              eos_token='<eos>',\n",
    "                              pad_token='<pad>',\n",
    "                              lower=True,\n",
    "                              batch_first=True,\n",
    "                              fix_length=20)\n",
    "\n",
    "        self.train_data, self.valid_data, self.test_data = \\\n",
    "            datasets.TranslationDataset.splits(path=filepath, exts=('.src', '.trg'),\n",
    "                                               fields=(self.SRC, self.TRG))\n",
    "\n",
    "        self.build_vocab()\n",
    "\n",
    "        print('number of training data : {}'.format(len(self.train_data)))\n",
    "        print('number of valid data : {}'.format(len(self.valid_data)))\n",
    "        print('number of test data : {}'.format(len(self.test_data)))\n",
    "\n",
    "        self.train_iterator, self.valid_iterator, self.test_iterator = data.BucketIterator.splits(\n",
    "            (self.train_data, self.valid_data, self.test_data), sort=True, sort_within_batch=True,\n",
    "            batch_size=self.batch_size, device=self.device)\n",
    " \n",
    "    def build_vocab(self, min_freq=5):\n",
    "        self.SRC.build_vocab(self.train_data, min_freq=min_freq)\n",
    "        self.TRG.build_vocab(self.train_data, min_freq=min_freq)\n",
    "        \n",
    "        print(f\"Unique tokens in source vocabulary: {len(self.SRC.vocab)}\")\n",
    "        print(f\"Unique tokens in target vocabulary: {len(self.TRG.vocab)}\")\n",
    "        \n",
    "elmo_dataset = ELMODataset(filepath=\"data\", batch_size=256, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b916cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterDecomposer:\n",
    "    def __init__(self, elmo_dataset, batch_size, max_word_in_sent, max_char_in_word, special_token_idx=[0, 1, 2, 3]):\n",
    "        self.elmo_dataset = elmo_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.max_word_in_sent = max_word_in_sent\n",
    "        self.max_char_in_word = max_char_in_word\n",
    "        self.special_token_idx = special_token_idx\n",
    "        \n",
    "        self.build_char_vocab()\n",
    "        \n",
    "    def build_char_vocab(self):\n",
    "        char_vocab = set([char for word in self.elmo_dataset.SRC.vocab.itos for char in word])\n",
    "        self.ctoi = {}\n",
    "        self.itoc = {}\n",
    "        \n",
    "        for idx, char in enumerate(char_vocab):\n",
    "            self.ctoi[char] = idx\n",
    "            self.itoc[idx]  = char\n",
    "            \n",
    "    def decompose(self, src):\n",
    "        # pad token이 1로 되어 있음\n",
    "        batch_char_embedding = np.ones((self.batch_size, self.max_word_in_sent, self.max_char_in_word)).astype(int)\n",
    "        \n",
    "        for batch_order_idx, sent in enumerate(src):\n",
    "            for word_order_idx, s in enumerate(sent):\n",
    "                if word_order_idx < self.max_word_in_sent - 1:\n",
    "                    if s in self.special_token_idx:\n",
    "                        batch_char_embedding[batch_order_idx, word_order_idx, 0] = s\n",
    "                        pass\n",
    "                    elif s not in self.special_token_idx:\n",
    "                        for char_order_idx, char in enumerate(self.elmo_dataset.SRC.vocab.itos[s]):\n",
    "                            if char_order_idx < self.max_char_in_word - 1:\n",
    "                                batch_char_embedding[batch_order_idx, word_order_idx, char_order_idx] = self.ctoi[char]\n",
    "                                                             \n",
    "        return torch.LongTensor(batch_char_embedding)\n",
    "    \n",
    "character_decomposer = CharacterDecomposer(elmo_dataset, batch_size=256, max_word_in_sent=20, max_char_in_word=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07dea8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 20, 6])\n"
     ]
    }
   ],
   "source": [
    "for batch in elmo_dataset.train_iterator:\n",
    "    src = batch.src\n",
    "    print(character_decomposer.decompose(src).shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31ea66be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import _LRScheduler, ReduceLROnPlateau, StepLR, LambdaLR\n",
    "\n",
    "import torchtext\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import Dataset, Field, BucketIterator\n",
    "    \n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "SEED = 1234\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8596008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, pad_idx, dropout=0.2):\n",
    "        super(CNN1d, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels  = embedding_dim, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size  = fs)\n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):       \n",
    "        embedded = self.embedding(text)\n",
    "        batch_size, word_len, char_len, emb_dim = embedded.size()\n",
    "        \n",
    "        # [batch * word_len, char_len, emb_dim]\n",
    "        embedded = embedded.reshape(-1, char_len, emb_dim)  \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat    = self.dropout(torch.cat(pooled, dim=1))\n",
    "        \n",
    "        print(f\"cat: {cat.shape}\")\n",
    "        \n",
    "        output = self.fc(cat)\n",
    "        output = output.reshape(batch_size, word_len, -1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, size, n_layers, f):\n",
    "        super(Highway, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.nonlinear = nn.ModuleList([nn.Linear(size, size) for _ in range(n_layers)])\n",
    "        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(n_layers)])\n",
    "        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(n_layers)])\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in range(self.n_layers):\n",
    "            gate = F.sigmoid(self.gate[layer](x))\n",
    "\n",
    "            nonlinear = self.f(self.nonlinear[layer](x))\n",
    "            linear = self.linear[layer](x)\n",
    "\n",
    "            x = gate * nonlinear + (1 - gate) * linear\n",
    "\n",
    "        return x\n",
    "    \n",
    "class ELMO_Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, output_dim, pad_idx, n_layers=2, bidirectional=True):\n",
    "        super(ELMO_Embedding, self).__init__()\n",
    "\n",
    "        n_filters = 100\n",
    "        filter_sizes = [3, 4, 5]\n",
    "\n",
    "        self.embedding = CNN1d(vocab_size, emb_dim, n_filters, filter_sizes, emb_dim, pad_idx)\n",
    "        self.highway   = Highway(size=emb_dim, n_layers=1, f=F.relu)\n",
    "        self.rnn       = nn.LSTM(emb_dim, hid_dim, n_layers, bidirectional=bidirectional)        \n",
    "        self.fc_out    = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedding               = self.embedding(src)\n",
    "        highway                 = self.highway(embedding)\n",
    "\n",
    "        output, (hidden, state) = self.rnn(highway)\n",
    "\n",
    "        batch_size, seq_len, _  = output.size()\n",
    "        output                  = output.reshape(batch_size, seq_len, -1, 2)\n",
    "\n",
    "        forward_hid, backward_hid = output[:, :, :, 0], output[:, :, :, 1]\n",
    "        \n",
    "        forward_pred  = self.fc_out(forward_hid)\n",
    "        backward_pred = self.fc_out(backward_hid)\n",
    "\n",
    "        return forward_pred, backward_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7a937d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, output_dim, character_decomposer, device, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in tqdm(iterator): \n",
    "        src = batch.src\n",
    "        src = character_decomposer.decompose(src).to(device)\n",
    "        trg = batch.trg.to(device).reshape(-1).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        fpred, bpred = model(src)\n",
    "        output_dim = fpred.shape[-1]\n",
    "        \n",
    "        fpred = fpred.reshape(-1, output_dim)\n",
    "        bpred = fpred.reshape(-1, output_dim)\n",
    "\n",
    "        forward_loss  = criterion(fpred, trg)\n",
    "        backward_loss = criterion(bpred, trg)\n",
    "        loss = forward_loss + backward_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, output_dim, character_decomposer, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src = batch.src\n",
    "            src = character_decomposer.decompose(src).to(device)\n",
    "            trg = batch.trg.to(device).reshape(-1).long()\n",
    "\n",
    "            fpred, bpred = model(src)\n",
    "            output_dim = fpred.shape[-1]\n",
    "\n",
    "            fpred = fpred.reshape(-1, output_dim)\n",
    "            bpred = fpred.reshape(-1, output_dim)\n",
    "            \n",
    "            forward_loss  = criterion(fpred, trg)\n",
    "            backward_loss = criterion(bpred, trg)\n",
    "            loss = forward_loss + backward_loss\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6eb75afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_VOCAB_SIZE = len(character_decomposer.ctoi)\n",
    "WORD_VOCAB_SIZE = len(elmo_dataset.TRG.vocab.stoi)\n",
    "EMB_DIM         = 200\n",
    "HID_DIM         = 512\n",
    "PAD_IDX         = elmo_dataset.SRC.vocab.stoi['<pad>']\n",
    "\n",
    "model     = ELMO_Embedding(CHAR_VOCAB_SIZE, EMB_DIM, HID_DIM, WORD_VOCAB_SIZE, PAD_IDX, n_layers=2, bidirectional=True)\n",
    "model     = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "127e174c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c69841e0b5248bdb0095e8d5aeb34db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n",
      "cat: torch.Size([5120, 300])\n",
      "embedding: torch.Size([256, 20, 200])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-223bf6cbf9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORD_VOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_decomposer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORD_VOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter_decomposer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-06e352fae703>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, output_dim, character_decomposer, device, clip)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbackward_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS  = 1\n",
    "PAITIENCE = 10\n",
    "\n",
    "n_paitience = 0\n",
    "best_valid_loss = float('inf')\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, elmo_dataset.train_iterator, optimizer, criterion, WORD_VOCAB_SIZE, character_decomposer, device)\n",
    "    valid_loss = evaluate(model, elmo_dataset.valid_iterator, criterion, WORD_VOCAB_SIZE, character_decomposer, device)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02}')\n",
    "    print(f'Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'Valid Loss: {valid_loss:.3f} | Train PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "    if n_paitience < PAITIENCE:\n",
    "        if best_valid_loss > valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'ELMO-LM_best.pt')\n",
    "            n_paitience = 0\n",
    "        elif best_valid_loss <= valid_loss:\n",
    "            n_paitience += 1\n",
    "    else:\n",
    "        print(\"Early stop!\")\n",
    "        model.load_state_dict(torch.load('ELMO-LM_best.pt'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d65754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
