{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.7.1\n",
      "Torchtext version: 0.8.0a0+0f911ec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import codecs\n",
    "import gensim\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\\nTorchtext version: {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd6c215c9b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# torch.backend.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(data_path, cv=10):\n",
    "  \n",
    "    revs = []\n",
    "    pos = codecs.open(os.path.join(data_path, \"rt-polarity.pos\"), \"r\", encoding='utf-8', errors='ignore').read()\n",
    "    neg = codecs.open(os.path.join(data_path, \"rt-polarity.neg\"), \"r\", encoding='utf-8', errors='ignore').read()\n",
    "    pos_list = [clean_str(sent) for sent in pos.split('\\n')[:-1]]\n",
    "    neg_list = [clean_str(sent) for sent in neg.split('\\n')[:-1]]\n",
    "    print('pos len', len(pos_list))\n",
    "    print('neg len', len(neg_list))\n",
    "    print('total len', len(pos_list) + len(neg_list) )\n",
    "  \n",
    "    for sent in pos_list:\n",
    "        datum = {'label': 1,\n",
    "                 'text': sent,\n",
    "                 'num_words': len(sent.split()),\n",
    "                 'split': np.random.randint(0,cv)\n",
    "                 }\n",
    "        revs.append(datum)\n",
    "\n",
    "    for sent in neg_list:\n",
    "        datum = {'label': 0,\n",
    "                 'text': sent,\n",
    "                 'num_words': len(sent.split()),\n",
    "                 'split': np.random.randint(0,cv)\n",
    "                }\n",
    "        revs.append(datum)\n",
    "\n",
    "    word_to_idx = {'@pad': 0}\n",
    "\n",
    "    for sent in pos_list + neg_list:\n",
    "        for word  in sent.split():\n",
    "            if word not in word_to_idx:\n",
    "                word_to_idx[word] = len(word_to_idx)\n",
    "\n",
    "    print(f'num of total data: {len(revs)}')\n",
    "    print(f'num of vocab: {len(word_to_idx)}')\n",
    "\n",
    "    df = pd.DataFrame(revs) \n",
    "    df.to_csv(os.path.join(data_path, 'polarity_df.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    print('save the data')\n",
    "    \n",
    "    return revs, word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos len 5331\n",
      "neg len 5331\n",
      "total len 10662\n",
      "num of total data: 10662\n",
      "num of vocab: 18765\n",
      "save the data\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data\"\n",
    "revs, word_to_idx = build_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data 9596\n",
      "test_data 1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghyunlee/miniconda3/envs/nlp/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TEXT   = torchtext.data.Field(sequential=True, tokenize=str.split, batch_first=True, fix_length=56, lower=True)\n",
    "LABEL  = torchtext.data.LabelField(sequential=False, dtype=torch.float)\n",
    "FIELDS = [('label', LABEL), ('text', TEXT)]\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(os.path.join(data_path, \"polarity_df.csv\"), fields=FIELDS, format='csv', skip_header=True)\n",
    "\n",
    "train_data, test_data = dataset.split(random_state=random.seed(SEED), split_ratio=0.9)\n",
    "\n",
    "print('train_data', len(train_data))\n",
    "print('test_data', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fd6c9a414d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(os.path.join(data_path, 'GoogleNews-vectors-negative300.bin.gz'), binary = True)\n",
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df69ef73a0754c03b73c14f8ab09cf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghyunlee/miniconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17863\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "w2v_vectors = []\n",
    "\n",
    "for token, idx in tqdm(TEXT.vocab.stoi.items()):\n",
    "    if token in w2v.wv.vocab.keys():\n",
    "        w2v_vectors.append(torch.FloatTensor(w2v[token]))\n",
    "    else:\n",
    "        w2v_vectors.append(torch.zeros(EMBEDDING_DIM))\n",
    "#         w2v_vectors.append(torch.distributions.Uniform(-0.25, +0.25).sample((EMBEDDING_DIM, )))\n",
    "\n",
    "print(len(w2v_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghyunlee/miniconda3/envs/nlp/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# making iterators\n",
    "train_iterator,  test_iterator = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device, \n",
    "    sort=False, \n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  741,     3,  4650,  ...,     1,     1,     1],\n",
      "        [   42,    38,    56,  ...,     1,     1,     1],\n",
      "        [ 2735,   982,     8,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    4,  4401,  8082,  ...,     1,     1,     1],\n",
      "        [   10,  2667, 13000,  ...,     1,     1,     1],\n",
      "        [   30,     2,  1602,  ...,     1,     1,     1]])\n",
      "torch.Size([64, 56])\n",
      "\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghyunlee/miniconda3/envs/nlp/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for a , b in train_iterator:\n",
    "    print(a)\n",
    "    print(a.size())\n",
    "    print()\n",
    "    print(b)\n",
    "    print(b.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels = embedding_dim, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = fs)\n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        #embedded = [batch size, emb dim, sent len]\n",
    "        conved = [F.tanh(conv(embedded)) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_DIM 17863\n",
      "EMBEDDING_DIM 300\n",
      "PAD_IDX 1\n",
      "UNK_IDX 0\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "print('INPUT_DIM', INPUT_DIM)\n",
    "print('EMBEDDING_DIM', EMBEDDING_DIM)\n",
    "print('PAD_IDX', PAD_IDX)\n",
    "print('UNK_IDX', UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,719,501 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test string: good\n",
      "Test string: 54\n",
      "\n",
      "before apply\n",
      "origianl: [ 0.04052734  0.0625     -0.01745605]\n",
      "torch_vector: tensor([ 2.2228, -0.3042, -0.0084], grad_fn=<SliceBackward>)\n",
      "\n",
      "after apply\n",
      "origianl: [ 0.04052734  0.0625     -0.01745605]\n",
      "torch_vector: tensor([ 0.0405,  0.0625, -0.0175], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# for check up (before applying word2vec)\n",
    "test = 'good'\n",
    "test_indx = TEXT.vocab.stoi[test]\n",
    "print(f'test string: {test}\\nTest string: {test_indx}')\n",
    "\n",
    "\n",
    "original_vector = w2v[test]\n",
    "torch_model_vector = model.embedding(torch.tensor([test_indx]))[0]\n",
    "print()\n",
    "print(f'before apply\\norigianl: {original_vector[:3]}\\ntorch_vector: {torch_model_vector[:3]}')\n",
    "\n",
    "# apply w2v\n",
    "TEXT.vocab.set_vectors(TEXT.vocab.stoi, w2v_vectors, EMBEDDING_DIM)\n",
    "pretrained_embeddings = torch.FloatTensor(TEXT.vocab.vectors)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "# for check up (after applying word2vec)\n",
    "torch_model_vector = model.embedding(torch.tensor([test_indx]))[0]\n",
    "print()\n",
    "print(f'after apply\\norigianl: {original_vector[:3]}\\ntorch_vector: {torch_model_vector[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# padding -> zero vectors\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX]\n",
    "\n",
    "# unknown token -> randomly initialized with uniform distribution\n",
    "model.embedding.weight.data[UNK_IDX] = torch.distributions.Uniform(-0.25, +0.25).sample((EMBEDDING_DIM,))\n",
    "model.embedding.weight.data[UNK_IDX]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adadelta(model.parameters())\n",
    "\n",
    "# BCEWithLogitsLoss automatically does softmax function\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model     = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #  l2 norm (weight contraints): 3\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param.clamp_(min=-3, max=3)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.276 | Train Acc: 88.63%\n",
      "\t Test. Loss: 0.436 |  Val. Acc: 80.31%\n",
      "Epoch: 02 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.199 | Train Acc: 92.55%\n",
      "\t Test. Loss: 0.466 |  Val. Acc: 79.44%\n",
      "Epoch: 03 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.131 | Train Acc: 95.38%\n",
      "\t Test. Loss: 0.514 |  Val. Acc: 78.79%\n",
      "Epoch: 04 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.075 | Train Acc: 97.97%\n",
      "\t Test. Loss: 0.556 |  Val. Acc: 79.90%\n",
      "Epoch: 05 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.043 | Train Acc: 99.06%\n",
      "\t Test. Loss: 0.654 |  Val. Acc: 78.48%\n",
      "Epoch: 06 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.027 | Train Acc: 99.51%\n",
      "\t Test. Loss: 0.654 |  Val. Acc: 79.11%\n",
      "Epoch: 07 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.016 | Train Acc: 99.80%\n",
      "\t Test. Loss: 0.660 |  Val. Acc: 80.49%\n",
      "Epoch: 08 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.010 | Train Acc: 99.92%\n",
      "\t Test. Loss: 0.688 |  Val. Acc: 79.95%\n",
      "Epoch: 09 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.007 | Train Acc: 99.93%\n",
      "\t Test. Loss: 0.701 |  Val. Acc: 80.18%\n",
      "Epoch: 10 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.97%\n",
      "\t Test. Loss: 0.729 |  Val. Acc: 80.13%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), os.path.join('weights', 'latest_weigths.pt'))\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t Test. Loss: {test_loss:.3f} |  Val. Acc: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.7737e+00,  5.1443e-03, -4.3022e+00, -1.1437e+00, -1.9547e+00,\n",
      "         1.3992e+00, -9.0374e-01,  2.9036e+00,  2.9538e+00, -2.3983e+00,\n",
      "         2.2909e+00, -1.9025e+00, -3.0645e+00,  3.7888e-01,  4.3808e+00,\n",
      "        -5.7399e+00, -5.0785e+00,  3.5388e+00, -4.4906e+00, -5.0073e+00,\n",
      "        -3.7470e+00,  5.3025e+00, -5.0526e+00,  5.4262e+00,  6.4762e-01,\n",
      "         6.8045e+00,  1.1273e-01,  4.8109e-01,  8.0179e+00, -4.0152e-01,\n",
      "         5.8624e-01,  6.3370e+00, -8.7900e-01, -2.7857e+00, -5.6614e-01,\n",
      "         6.0901e+00,  1.1505e+00, -7.5684e-01, -2.1399e+00, -2.5490e+00,\n",
      "         3.8377e+00, -2.7731e+00,  1.3195e+00, -1.7095e+00,  1.9329e+00,\n",
      "        -1.6782e+00,  1.2829e+00,  2.6101e+00,  7.9525e-01,  3.7645e+00,\n",
      "         1.3969e+00,  6.9994e+00, -1.1810e-01, -5.6805e+00,  1.8092e-01,\n",
      "         2.2383e+00,  5.4572e+00,  2.4550e+00,  1.5839e+00,  1.8229e+00,\n",
      "        -4.5187e+00, -3.4050e+00,  4.3651e+00, -2.8964e+00])\n",
      "tensor([-3.4420, -0.0412, -0.9857,  1.1341, -3.6155,  3.3118,  1.3191, -0.2446,\n",
      "        -1.2205,  0.3567,  3.6447, -4.1184,  2.5024,  3.9615,  0.1043, -4.0900,\n",
      "        -1.8248, -0.7211,  1.6607,  0.9554,  1.8334, -1.0210,  0.7308, -1.0103,\n",
      "         4.8887,  0.1128,  2.2249, -0.1607,  0.5335,  1.0291,  0.6389,  0.3111,\n",
      "         0.3861, -2.6744, -1.5701,  2.8787,  6.4951,  1.7433,  2.1189, -1.0255,\n",
      "         0.0969, -1.3018,  1.3539,  0.5143,  3.3249,  3.6150,  4.2246,  2.1994,\n",
      "         2.8260, -0.5523,  3.7743,  3.2296,  1.7273,  0.0379, -0.8833, -3.5482,\n",
      "         3.1573, -1.3004, -0.6157,  4.4823, -0.5688,  0.6707,  1.5255, -2.5283])\n",
      "tensor([-1.5552, -3.5658, -1.3155,  0.0407,  0.1985,  1.8577,  0.7496, -1.4272,\n",
      "        -1.8856,  0.3438, -1.8003,  1.2056,  1.4717, -6.2616,  4.4676, -1.1803,\n",
      "         2.1235, -6.2158, -0.5331, -2.3242, -0.6824, -0.1849,  0.5531, -2.0298,\n",
      "         0.0976, -2.1064,  4.1199, -1.7053,  3.2940, -2.2630,  2.6207,  0.6077,\n",
      "        -5.0953, -0.2623,  1.7636, -0.1016,  6.5396,  3.9146, -1.7059,  5.8218,\n",
      "         1.4384, -4.2878,  3.0785, -3.9498,  1.8119, -6.7074,  4.2407, -1.4176,\n",
      "        -3.8247,  3.9532,  3.4774,  4.0618, -0.4956,  6.1142,  4.6272, -4.2130,\n",
      "        -1.6501,  3.3766, -5.0825,  1.4887, -1.7105,  1.5839,  1.0598, -1.4578])\n",
      "tensor([ 1.4117,  2.5129, -0.9079, -2.6194, -2.4289, -1.5057,  2.2098,  1.4686,\n",
      "        -1.9105,  3.1594,  5.1289,  3.4657,  0.8967,  5.1537,  6.8774, -2.7333,\n",
      "        -4.4633, -1.5472, -3.9984,  2.6409,  3.3593,  2.7312, -1.0173,  2.1202,\n",
      "         6.0645,  2.7094,  0.6536, -0.9981,  1.0696,  7.7715, -2.6211, -1.3922,\n",
      "         0.7008, -1.5550,  2.8120,  3.1446,  0.9531, -2.1891, -3.6083,  4.4781,\n",
      "        -0.3138,  0.6814])\n",
      "tensor([ 1.9517, -0.2944,  3.0821,  1.9027, -1.4348,  2.4632,  4.4886,  3.8246,\n",
      "         4.7515,  3.8507,  1.9986,  0.5319, -0.0627,  3.7709,  0.2195, -4.3241,\n",
      "        -1.0217,  5.7799, -2.0797, -0.1117,  2.2747, -4.1533, -6.0238,  0.8865,\n",
      "        -1.1594,  4.5769,  2.1423,  2.3490,  1.0806,  2.8285, -2.3262,  3.5043,\n",
      "        -2.6329, -6.2170,  3.5091,  4.3732, -0.8488, -3.5568, -0.8534, -5.9697,\n",
      "         3.5297,  2.3744,  2.4799,  1.5657,  3.8363,  0.0205,  2.7932,  1.3594,\n",
      "        -3.0506, -3.1976, -2.7898,  1.3017, -4.2204,  1.0090, -2.0058,  0.7329,\n",
      "        -0.5777,  1.5784,  4.4538, -1.3390,  0.2514, -4.2473,  2.3515, -1.6195])\n",
      "tensor([-4.4563,  4.8016,  3.1269, -0.1389,  4.8242,  2.5054,  1.6867, -3.3291,\n",
      "         6.7630, -0.0533, -5.2368,  0.7296, -5.0009,  2.1155, -0.8717, -1.0674,\n",
      "         4.5234,  0.4012, -1.3753, -4.1534, -1.9478,  5.8947, -0.1509,  0.7355,\n",
      "        -0.3921, -5.7151,  0.4383, -2.8405,  1.6371, -6.7126, -1.4732, -5.2770,\n",
      "         3.2651,  0.6240,  1.2641, -0.3054,  1.7939,  4.1330, -1.9204,  1.9375,\n",
      "        -2.0496, -1.7011, -4.7301, -1.2761, -2.4013, -3.4273,  1.2160,  1.0237,\n",
      "         2.0347, -0.4432, -1.2667,  4.8222,  1.4735,  0.0983,  2.1712, -2.2901,\n",
      "        -0.0999, -1.1512,  0.4534,  0.0223, -1.6040,  2.8756, -2.9952, -4.0582])\n",
      "tensor([ 1.5942, -4.7064,  3.0254, -1.6594,  1.6430, -1.4374, -0.3158, -1.8208,\n",
      "        -1.9444, -2.1374, -0.2985,  0.3804,  4.9937,  0.6204, -2.8622, -0.8594,\n",
      "         2.7290, -2.5003,  0.9646, -6.6863, -5.3469,  5.9783,  2.0808,  0.7509,\n",
      "         4.8558,  2.6866,  3.8110,  2.3684, -2.4604, -0.8074, -3.7713,  1.3603,\n",
      "        -2.8149,  1.6827, -4.5015,  3.6564, -1.7565,  0.9445,  0.9726, -1.1486,\n",
      "        -0.2661, -1.7019,  3.9055,  1.4581, -0.3030, -0.9332, -1.8465,  0.1040,\n",
      "         3.2044, -0.5079,  0.5840, -1.0375, -3.0180, -4.6775, -2.9978, -1.6327,\n",
      "         4.9494, -0.0185, -5.3932, -2.3563, -3.7149,  3.3316, -2.0172, -5.7398])\n",
      "tensor([-0.9889, -0.4137, -4.7808,  5.0979, -2.4062,  0.7801, -3.1283,  2.7510,\n",
      "        -3.7622, -0.2897, -0.2004,  1.1688, -3.7623,  1.1567,  2.0040,  2.4500,\n",
      "         1.7878,  5.3953,  3.3095,  4.8508, -1.3437, -2.3341,  8.6541,  3.5303,\n",
      "        -2.8143, -2.4030,  2.4064, -1.2396,  1.4728,  1.7199,  2.1412, -0.4934,\n",
      "         0.3354, -0.2749,  0.6398, -3.8745, -3.8564, -0.3046, -1.7134,  3.3702,\n",
      "        -0.2383, -8.6758, -1.8499, -0.9295,  3.7883,  5.0905,  3.8594, -3.3903,\n",
      "        -3.8337,  3.7734, -2.4869, -6.3781,  0.4299,  2.4734, -2.2743, -5.4173,\n",
      "        -2.5588,  0.6987, -0.7070,  1.8743,  6.7722,  0.2264, -3.8069,  2.3559])\n",
      "tensor([ 3.4178e+00,  6.8980e+00, -3.1315e+00, -6.5103e-01, -3.4371e+00,\n",
      "        -2.9609e-01, -6.9320e+00, -2.7903e+00, -1.0410e+00, -5.2339e-01,\n",
      "        -1.9399e+00,  3.3730e+00, -7.6804e-01,  1.1816e+00, -2.3649e+00,\n",
      "         6.2475e-01,  2.5612e+00,  1.9355e+00, -1.5628e+00,  2.2527e-01,\n",
      "         3.3064e+00,  9.7653e-02, -5.4175e-01,  3.1493e+00,  7.3240e-01,\n",
      "         1.3122e+00, -2.3337e+00,  1.0385e+00,  3.3902e+00,  1.5181e+00,\n",
      "         3.9210e+00,  5.7295e+00, -4.0573e+00, -1.3900e+00, -4.5449e+00,\n",
      "         3.1809e+00,  1.7319e+00, -2.1042e+00, -3.1886e+00,  3.9019e+00,\n",
      "        -2.0097e+00, -2.5937e+00,  2.8015e-01, -2.8163e+00, -3.3865e+00,\n",
      "         2.0252e+00, -1.2293e+00,  2.7581e+00, -2.0030e+00,  1.7832e+00,\n",
      "         1.5080e+00, -4.4099e-03,  2.4881e+00, -1.6030e-01, -9.4791e-01,\n",
      "        -3.0570e+00,  5.4433e+00, -1.6629e+00, -3.0384e+00, -2.5321e+00,\n",
      "        -3.6292e+00,  4.4787e+00, -8.7256e-01, -3.8109e+00])\n",
      "tensor([ 0.1539,  2.0533, -2.3571,  1.1808, -3.3406,  3.8487,  1.9324, -1.2298,\n",
      "        -0.3389,  0.9165, -0.7353, -3.8974,  2.4002,  1.5097,  2.1976,  4.1322,\n",
      "         0.8962, -4.2161, -6.1060, -0.0373, -5.8489,  4.4645, -0.0554, -1.5008,\n",
      "        -5.3844, -1.3495,  2.4095,  1.6492, -2.3954, -2.5654,  3.9859, -2.1752,\n",
      "         4.2446, -2.0660,  0.9858,  7.3905, -2.8917,  4.4600, -1.9570,  1.0419,\n",
      "         2.4796, -4.5901, -0.0861, -1.5258,  1.1098, -1.2114,  0.5293, -3.5669,\n",
      "        -1.7907, -0.2143,  1.7116,  5.8730, -2.0864, -0.8219,  1.8035, -4.5288,\n",
      "         1.1321,  1.4410, -5.0913,  1.7666,  1.4111, -7.5306, -0.6249,  0.1560])\n",
      "tensor([-1.7228,  0.7016, -1.9217,  3.3400,  6.9636,  0.4622,  1.1645,  4.2131,\n",
      "         2.5781,  7.1639,  5.9125, -4.6962,  3.1202, -2.8173, -0.9522, -2.7277,\n",
      "        -4.0537,  0.3439, -0.8175,  1.5620,  0.3641, -5.4808,  4.0229, -0.9286,\n",
      "        -3.9211,  7.1025,  0.8663, -3.5116,  4.0987, -2.6645, -2.6654, -2.5577,\n",
      "        -0.8851, -6.7131,  4.9819,  3.1058, -3.8478, -0.4840,  3.2818, -2.9715,\n",
      "        -3.4777,  0.4448,  3.7091,  1.0941,  1.1906, -1.4255,  1.3720,  1.6283,\n",
      "         1.3389, -3.4108, -1.8920, -2.4842, -3.1827, -2.8165, -2.2868,  0.8120,\n",
      "         5.5199, -1.8192, -0.4455,  0.0505, -1.9093,  1.2166, -1.1293, -0.0866])\n",
      "tensor([-3.5101, -3.4029, -3.9095,  2.9994, -2.3333,  0.8471, -3.6270,  3.6697,\n",
      "        -3.8836, -0.4652, -0.2010, -1.0396,  1.7605, -0.0586,  6.0700, -4.7800,\n",
      "         1.8949,  3.5609, -1.8464,  2.1654, -7.0362, -2.1622,  0.0889, -2.6698,\n",
      "         2.4383,  4.5865,  2.6299, -1.9216,  1.6813, -4.7025,  4.8105, -2.6994,\n",
      "        -0.5901,  3.4053, -2.3231,  2.6165,  5.3202, -1.0935,  1.9504,  2.7450,\n",
      "         1.1077, -3.2270,  1.5478,  0.2576, -0.9221,  1.2735, -0.2470,  0.7550,\n",
      "        -1.0260,  2.7083, -1.6997,  3.3658,  1.8269,  1.3023, -1.6536, -1.7864,\n",
      "        -2.6061,  5.4478,  1.6501, -1.3869,  0.8679, -3.6733, -0.0958,  1.9300])\n",
      "tensor([-1.2173,  2.5618,  0.5585, -4.4948,  2.3105,  2.5732, -1.1249,  3.0860,\n",
      "        -3.2313, -0.7262, -1.4190,  4.1526, -0.5524, -5.8293,  1.0440, -3.2873,\n",
      "        -3.0588,  0.7893,  6.5451, -2.6396,  1.1757, -2.8545,  2.9392, -6.4040,\n",
      "        -1.1463, -6.5717,  0.3525,  2.6707,  5.4706, -0.4141,  0.3099, -2.0632,\n",
      "         6.8386, -4.4830,  8.1435, -1.7640, -5.0267, -1.3645, -0.9637,  4.7304,\n",
      "        -0.3348, -0.7437,  0.3247,  3.3384, -2.4048, -3.7006,  6.4366, -4.2053,\n",
      "        -0.6707, -0.5572,  5.7753, -0.2519,  1.3907, -1.1829, -3.6519, -0.6372,\n",
      "         3.9412, -0.2831, -3.4149,  1.4967, -1.2780, -1.5275,  2.4525, -0.5723])\n",
      "tensor([-4.2890,  5.0797,  4.1187,  3.7796,  4.0839, -0.8582, -6.4530, -2.6582,\n",
      "        -0.4631, -1.9416, -1.5339, -0.7171, -2.5769,  2.7716, -3.1742, -0.2856,\n",
      "        -2.3130,  3.4586, -1.5129, -2.4504, -3.8327, -3.8875, -0.7412, -3.0711,\n",
      "        -2.1392,  3.4624, -0.7039, -3.7451, -2.7241, -0.5755, -0.2439, -1.8883,\n",
      "        -5.2600,  0.1748, -0.1292,  4.5333,  3.0606, -0.2684, -1.7743, -5.6140,\n",
      "         2.8038,  2.3193,  3.1795, -3.4989,  2.6890, -0.2292, -4.5188, -0.1578,\n",
      "         1.8522, -2.0661, -1.6601, -2.9952, -1.1672,  0.4435, -1.2365,  1.4276,\n",
      "        -2.0326, -3.4979,  1.3140, -1.5044,  3.8859, -0.1328,  2.2782,  2.7248])\n",
      "tensor([ 1.9194, -1.4591,  5.9179, -2.6634,  1.7893,  7.5143, -3.5195, -2.2715,\n",
      "         5.4180,  0.7727, -4.0036, -7.0692, -0.3272, -0.7912,  3.6324,  1.4081,\n",
      "        -0.1794, -0.3349,  2.7948, -7.2450, -2.7852, -1.9972, -5.5514, -1.9977,\n",
      "         3.9761, -2.9529, -1.7789,  0.0906,  5.1166,  1.5084, -2.1639,  0.5797,\n",
      "        -1.7996,  3.0327, -2.2345,  1.8818,  1.3453, -2.8817,  4.9822,  7.0774,\n",
      "        -1.8975, -1.8553,  4.4717, -3.8972, -2.2428, -0.0825,  0.9722, -2.3517,\n",
      "        -1.1040,  0.9284,  1.1749,  1.2926,  1.6968, -1.4959, -2.0155,  1.2640,\n",
      "         0.9198, -0.2098,  0.5104,  1.1040, -2.6982, -0.7265,  0.3977, -0.0637])\n",
      "tensor([-4.0932, -2.4312, -4.5768, -0.8722, -0.2387, -2.1074,  3.3534,  3.6483,\n",
      "        -1.9581,  2.0595, -4.1165, -2.8983,  1.2043, -2.0395, -2.6678,  0.2078,\n",
      "        -2.9311, -3.9523, -2.0180,  1.9276,  1.0875, -4.4217,  5.0562, -4.7645,\n",
      "         3.1261,  1.7669,  0.1719,  3.3102, -1.6937,  2.1273,  3.6014,  0.7357,\n",
      "         1.3132,  1.1780, -1.6242, -7.2158, -0.7029, -2.2278, -1.0112,  1.6855,\n",
      "         0.1662, -1.5142,  4.5034,  0.8902, -1.1957,  4.4663, -2.0655,  0.5003,\n",
      "         0.0176,  0.9492, -4.5623,  2.9080,  2.1133,  2.8660, -0.1131,  0.1349,\n",
      "         1.4125,  1.9110,  6.5164, -4.3109, -0.4482, -1.3375, -0.0964, -0.4551])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8456, -0.3221,  0.9992,  2.0143,  1.1635,  1.0027, -0.6904,  4.3192,\n",
      "        -0.7128, -1.5601,  0.5725,  1.8753, -0.2105,  2.6226, -2.9754,  4.8488,\n",
      "        -4.8531, -8.3488,  4.2852, -6.5219,  0.6712, -1.8527, -1.7970, -1.8057,\n",
      "         1.2812, -0.7504, -3.1256, -7.1719,  2.8686, -2.3451,  0.0779,  5.6151,\n",
      "         2.9809, -0.7065,  2.1750, -2.5555, -4.7568,  1.7967, -2.2392,  2.2917,\n",
      "         0.5784,  4.6005,  4.6674,  1.3962, -4.9643, -2.9012, -1.3785, -1.2938,\n",
      "         0.8299, -0.8498,  1.0485, -2.5579,  3.3810, -1.4089, -1.8781,  2.2435,\n",
      "         0.2126, -1.1327, -1.8017, -1.8398,  1.9083,  1.3942,  0.7747,  1.6275])\n",
      "Test Loss: 0.434 | Test Acc: 80.46%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join('weights', 'latest_weigths.pt')))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "film\n",
      "is\n",
      "terrible\n"
     ]
    }
   ],
   "source": [
    "my_sentence = \"this film is terrible\"\n",
    "\n",
    "for word in my_sentence.split():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
